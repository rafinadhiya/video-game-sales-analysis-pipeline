{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectation (GX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Rafina Dhiya Pradani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great Expectations (GX) is used to check and ensure data quality. Here are the GX checks I will perform:\n",
    "\n",
    "1. **Unique Values**: Ensures all values in the `unique_id` column are distinct, avoiding duplicates to maintain data integrity.\n",
    "\n",
    "2. **Year Range**: Validates that the `year` column only contains values between 1980 and 2024, ensuring relevance.\n",
    "\n",
    "3. **Valid Platform Set**: Confirms that `platform` values are valid (e.g., Wii, NES, GB), identifying potential data entry errors.\n",
    "\n",
    "4. **Correct Data Type**: Ensures all values in the `name` column are strings, maintaining consistency for text operations.\n",
    "\n",
    "5. **Median Sales Range**: Validates that the median of `global_sales` is between 0 and 30 million units, reflecting realistic industry trends.\n",
    "\n",
    "6. **Quantile Check**: Ensures `na_sales` quartile values fall within a realistic range, verifying the distribution reflects market conditions.\n",
    "\n",
    "7. **Regex for Sales Data**: Confirms `eu_sales` contains only numeric values for accurate quantitative analysis.\n",
    "\n",
    "These checks will help maintain accurate, clean, and reliable data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import great_expectations as gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully imported the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unique_id                      name platform  year         genre publisher  \\\n",
      "0          1                Wii Sports      Wii  2006        Sports  Nintendo   \n",
      "1          2         Super Mario Bros.      NES  1985      Platform  Nintendo   \n",
      "2          3            Mario Kart Wii      Wii  2008        Racing  Nintendo   \n",
      "3          4         Wii Sports Resort      Wii  2009        Sports  Nintendo   \n",
      "4          5  Pokemon Red/Pokemon Blue       GB  1996  Role-Playing  Nintendo   \n",
      "\n",
      "   na_sales  eu_sales  jp_sales  other_sales  global_sales  \n",
      "0     41.49     29.02      3.77         8.46         82.74  \n",
      "1     29.08      3.58      6.81         0.77         40.24  \n",
      "2     15.85     12.88      3.79         3.31         35.82  \n",
      "3     15.75     11.01      3.28         2.96         33.00  \n",
      "4     11.27      8.89     10.22         1.00         31.37  \n"
     ]
    }
   ],
   "source": [
    "# path file\n",
    "file_path = 'data/P2M3_afi_data_clean.csv'\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# show the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to Great Expectation DataFrame\n",
    "df_ge = gx.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully loaded dataframe and changed dataframe to great expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 1 To be Unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expect_column_values_to_be_unique expectation ensures that each value in the `unique_id` column is unique, so there are no duplicates. This maintains the integrity of the dataset, ensuring that each entry has a different ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring that the 'unique_id' column has unique values\n",
    "df_ge.expect_column_values_to_be_unique(column=\"unique_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation of the `unique_id` column as a column that has unique values ​​was successful. There are no duplicate values ​​in this column. In other words, the `unique_id` column meets expectations for maintaining data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 2 To be Between min_value and max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expectation ensures that the year column only contains year values ​​between 1980 and 2024. This helps ensure that the data does not include irrelevant years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring that the values ​​in the 'year' column are between 1980 and 2024\n",
    "df_ge.expect_column_values_to_be_between(column=\"year\", min_value=1980, max_value=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation that the year column only contains values ​​between 1980 and 2024 has succeeded. This indicates that there are no irrelevant or incorrect years in the dataset. All data in this column meets the specified validation criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 3 To be in Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekspektasi ini memastikan bahwa kolom platform hanya berisi nilai-nilai yang valid, seperti Wii, NES, GB, dan sebagainya. Validasi ini berguna untuk mendeteksi kesalahan entri data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that the 'platform' column only has values ​​from the list of valid platforms\n",
    "valid_platforms = [\n",
    "    'Wii', 'NES', 'GB', 'DS', 'X360', 'PS3', 'PS2', 'SNES', 'GBA',\n",
    "       '3DS', 'PS4', 'N64', 'PS', 'XB', 'PC', '2600', 'PSP', 'XOne', 'GC',\n",
    "       'WiiU', 'GEN', 'DC', 'PSV', 'SAT', 'SCD', 'WS', 'NG', 'TG16',\n",
    "       '3DO', 'GG', 'PCFX'\n",
    "]\n",
    "\n",
    "df_ge.expect_column_values_to_be_in_set(column=\"platform\", value_set=valid_platforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation that the `platform` column only contains values ​​from the list of valid platforms has succeeded. This shows that all platforms in the dataset fit the valid categories and there is no incorrect or irrelevant data. With this validation, the integrity of the data in the `platform` column is guaranteed, ensuring that further analysis can be performed without interference from invalid values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 4 To be in Type List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validation ensures that all values ​​in the `name` column have a string (object) data type. This is important for maintaining data consistency, especially if the column is used for text operations, such as search or category analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the 'name' column has a string (object) data type.\n",
    "df_ge.expect_column_values_to_be_in_type_list(\n",
    "    column=\"name\",\n",
    "    type_list=[\"str\", \"object\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation that the `name` column has a string (object) data type has **succeeded**. All values ​​in this column match the expected data type, so the data is consistent and ready for text-based analysis or manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 5 Median to Be Between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating that the median of the global_sales column is in the range of 0 to 30 million units sold ensures that the global sales data is within a realistic range based on gaming industry trends. This is important to maintain the reliability of the data analysis and ensure that the dataset is not affected by anomalies or data input errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"observed_value\": 0.17,\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that the median in the 'global_sales' column is in the range 0 to 30\n",
    "df_ge.expect_column_median_to_be_between(column=\"global_sales\", min_value=0, max_value=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "**Validation that the median in the `global_sales` column is in the range of 0 to 30 has been successful.** The observed median of 0.17 million units indicates that most games in the dataset have relatively small global sales. This ensures that the global sales data is within a realistic range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 6 Quantile Values to Be Between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validation ensures that the quartile distribution of the `na_sales` column falls within a specified range. This is important for examining sales distribution patterns in North America, helping to identify low- and high-selling games, and ensuring that the dataset reflects realistic market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"observed_value\": {\n",
       "      \"quantiles\": [\n",
       "        0.25,\n",
       "        0.5,\n",
       "        0.75\n",
       "      ],\n",
       "      \"values\": [\n",
       "        0.0,\n",
       "        0.08,\n",
       "        0.24\n",
       "      ]\n",
       "    },\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensures that the quartile distribution of 'na_sales' falls within a specified range\n",
    "result_na_sales = validator.expect_column_quantile_values_to_be_between(\n",
    "    column=\"na_sales\",\n",
    "    quantile_ranges={\n",
    "        \"quantiles\": [0.25, 0.5, 0.75],\n",
    "        \"value_ranges\": [[0, 5], [0, 10], [0, 20]]\n",
    "    }\n",
    ")\n",
    "\n",
    "result_na_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation that the quartile distribution of the `na_sales` column falls within the specified range has been **successful**. All quartiles (25%, 50%, and 75%) fall within the specified range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation 7 Values to Match Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation ensures that all values ​​in the `eu_sales` column are only numbers (either whole numbers or decimals). This is important so that the `eu_sales` column can be used for quantitative analysis, such as calculating total sales or analyzing trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 16291,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensures that all values ​​in 'eu_sales' are only numbers\n",
    "result_eu_sales = validator.expect_column_values_to_match_regex(column=\"eu_sales\", regex=r\"^\\d+(\\.\\d+)?$\")\n",
    "result_eu_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation shows that the data in the `eu_sales` column is free from non-numeric values ​​and can be used directly for analysis or calculations. This ensures the consistency and reliability of sales data in the European region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "The Great Expectations (GX) validations were completed successfully, ensuring the dataset is clean and reliable for analysis. Here’s a summary:\n",
    "\n",
    "1. **Unique Values**: The `unique_id` column has no duplicate values, keeping the dataset accurate.\n",
    "   \n",
    "2. **Year Range**: The `year` column contains only years between 1980 and 2024, confirming all data is relevant.\n",
    "\n",
    "3. **Valid Platforms**: The `platform` column includes only valid platform names, ensuring consistent and correct data.\n",
    "\n",
    "4. **Consistent Data Types**: The `name` column has only text values, making it ready for further analysis.\n",
    "\n",
    "5. **Realistic Median Sales**: The median `global_sales` value is within a realistic range, showing reliable sales trends.\n",
    "\n",
    "6. **Valid Quartiles**: The quartile values in `na_sales` are within the expected range, reflecting realistic sales in North America.\n",
    "\n",
    "7. **Numeric Sales Data**: The `eu_sales` column has only numbers, ensuring it’s ready for calculations and analysis.\n",
    "\n",
    "These validations ensure that the dataset is clean, reliable, and ready for further analysis, minimizing errors and maintaining the integrity of insights derived from the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
